

### 1. What is Machine Learning?
- Find a procedure to map the input to the output. The input and outputs are available and the relation between them is not known
	- If the mapping between input and output is already known, then machine learning is not required
	- If the mapping between input and output changes over time, machine learning can be used. Ex: finding if a person will purchase a product or not
	- Machine learning cannot be used when there is less data or there is no pattern in the data(i.e. data is seemingly random)
- Can be viewed as
	- Pattern recognition in data, this is used in the case where there is input data but no output 
	- Function approximation using a function and an error estimate
	- Optimization problem where we try to minimize the error
- Based on the data and the desired output, we can categorize ML as follows
	- Supervised learning 
		- Classification
		- Regression
	- Unsupervised learning
		- Clustering
		- Dimensionality reduction
- A model or pattern is learnt from the training data
	- A model is said to **generalize** well if it can correctly predict the output for the test data
	- The test data is similar to the train data, but not the same as the train data
	- One goal of ML is to minimize the generalization error (which is the error over all possible mappings of input and output)
		- Getting all the mapping between input and output is not possible, to estimate the generalization error, we split the data into train test and validation data. We can use the validation set to get the estimate of the generalization error of the model 
- Types of models
	- Inductive and transductive models
		- What is Inductive Bias?
			- The assumptions that are required to make the learning possible
			- One inductive bias is choosing what function our ML algorithm will approximate. I can assume that the data will fit into a polynomial curve and use polynomial regression
		- Inductive models induce a model
		- Transductive models does not induce a model. Example is the KNN classifier, decision trees and linear SVM
	- Online learning vs Offline learning
		- Online learning: train the model as new data is obtained
		- Offline learning: The trained model is frozen, it is not further trained on the new data available
	- Generative vs Discriminative model
		- Discriminative models differentiates between the classes
		- Generative models output the class that will likely be generated for the given input 
	- Parametric vs Non-parametric model: This is not regarding hyperparameters, but the parameters that we initialize before training
		- In a parametric model, the number of parameters is always fixed. This will not change with more data
		- In a non-parametric model, the number of parameters will depend on the number of data points. Example in decision trees, we learn the split values for each attribute. This is a parameter that is learnt during training. The number of parameters will vary given the dataset
		- ~~In a parametric model, the parameters that give the minimum accuracy are learnt during the model training phase. Example is the weights in the neural network.~~
			- ~~NOTE: In a parametric model, we will always initialize the parameters with random values(based on some constraints). Decision Tree is not a parametric model, we don't initialize any parameters and it is also a transductive model~~
		- ~~In non-parametric model, no weights are learnt during the training phase. Example is the KNN classifier. Here K is a hyperparameter set by the user, the K value is not learnt during training~~
			- ~~Similar inputs will have similar outputs. This is the basis on with the non-parametric models work~~
			- ~~We also don't assume the probability density from which the input data is drawn from.~~ 

### 2. Standard practices
#### 2.1 Splitting data 
- Data records are randomized and is split into three parts, train, validation and test data
	- When splitting the data, the distribution must be similar. if there 40% +ve classes in the data, the train and test should also have the same proportion of the +ve samples. This is called **stratified sampling**
- Only the train data is used to train the model. The validation data is used to select the best model(models that are trained with different parameters). The test set is used as estimate of the best model that was selected
	- Finally the model is evaluated using the test set
	- When reporting the accuracy of our model, we use the test set and not the validation set. This is because we have already used the validation set error to select the best model
- The processing the steps like normalization is done based on the metrics gathered from the training data
	- Let's min max normalization needs to be performed, the min and max is obtained only from the train data 
	- When predicting, the min max obtained in train data is used to normalize the input test data
#### 2.2 Training and selecting a model
- Training a Model
	- Training is done on different parameters of the model, to choose the best model, the model is evaluated using the validation data. 
	- When choosing a model, chose the model with the least complexity and the minimum generalization error. Why?
		- Let's say our data is sampled from a third degree polynomial curve with some noise
		- When our model has a lesser degree polynomial(less that 3), the generalization error is higher (underfitting)
		- When our model has a really high degree polynomial (greater than 3), the model will also learn the noise in the data (overfitting)
- Selecting a model
	- K fold cross validation: 
		- Divide the train data into K sets, train k models independently with k-1 sets of data and validate using the kth set of data
	- Leave one out: 
		- N-fold cross validation, leave only one data sample for validation
#### 2.3 Evaluation classification model
- Accuracy
	- How many samples are classified correctly 
	- Accuracy is not sufficient to measure a model, let the data have 80% of +ve samples, and the model classifies all data points as +ve and get 80% accuracy
	- Correctly classified: 
		- True positives
		- True negatives
	- Incorrectly classified: 
		- False positives: Negatives samples but predicted as positive samples
		- False negatives: Positive samples but predicted as negative samples
- False positive rate/False Alarm:
	- (False positive)/(total actual -ve samples)
	- FP/(FP + TN)
- False negative rate/Miss:
	- (False negative)/(total actual +ve samples)
	- FN/(FN + TP)representation
- True positive rate/Recall:
	- TP/(TP+FN)
	- Out of all the actual positive classes, how much the model classified correctly
	- When recall is less, there is more false negatives in the classification
- Precision:
	- TP/(TP+FP)
	- Out of all the positive predictions that are made, how much are actually correct
	- When precision is less, there is more false positives in the classification
- ROC curves: 
	- Usually, in classification, we will have a threshold after which the data point is classified +ve or -ve. The accuracy will be affected by the threshold we choose. 
	- The ROC curve can be used to evaluate model independent of the threshold
		- The model with higher area under the ROC curve is a better model
	- The ROC curve plots the (false positive rate(miss), true positive rate(recall)) for each value of the threshold
		- The threshold can be chosen based on the cost, i.e. if false positives are less desirable, then the threshold is chosen in such a way that false positives are also minimized along with the other evaluation metrics 
- Confusion matrix:
	- Used to represent the predictions of a classifier
	- NxN matrix. The diagonal represent the classes that are correctly classified, for every other entry the row will represent the prediction and the column will represent the actual class