
### 1. What is an Algorithm
- A finite sequence of instructions that transforms the give input to an output
#### 1.1 Characteristics of an Algorithm
- Correctness of an algorithm: 
	- The algorithm stops and outputs the correct value for any given input 
- Definiteness
	- Each step of the algorithm should be unambiguous
- Minimizing the use of resources
	- Minimizing the resource utilization in desirable in an algorithm
	- Resource can be memory, time to compute, number of processor cores or number of API calls etc
- An algorithm should be deterministic
	- The algorithm will output the same value for the same input value
	- The algorithm terminates for all given inputs
	- The path the algorithm takes can be determined and is same of the same input
	- Exception: Randomized algorithms do not have a deterministic output
- An algorithm should be efficient
	- An algorithm efficiency should be denoted in a format that is hardware independent. (Using asymptotic notations)

### 2 Asymptotic notations
- What is input size?
	- Size of the input is problem dependent
	- Example:
		- For an array, the input size is the number of elements in the array
		- For multiplication of two numbers, the input size is the number of bits used to represent each number
- Running time of an algorithm?
	- Represent the running time in terms of the number of times the instruction is executed multiplied by the time taken to execute the instruction 
	- It is assumed that the time taken to execute an instruction is constant
	- This leaves us with the number of times the instruction is executed which depends on the input size
- Asymptotic Notation
	- Represents how the running time increases with the increase in input size
		- For example, finding if a number is odd or even is constant time no matter what the size of input is (using the last bit of the number)
		- Searching for an element in a list of element, the running time increases linearly with the increase in input size
		- Finding all the permutations of a list of unique numbers: running time will be factorial of the input size
#### 2.1 Theta notation: Θ
- A function f(n) belongs to a family of functions Θ(g(n)) if there exists positive constants c<sub>1</sub>, c<sub>2</sub>, n<sub>0</sub> such that
	- 0 <= c<sub>1</sub>g(n) <= f(n) <= c<sub>2</sub>g(n) for all n >= n<sub>0</sub>
- When f(n) belongs to Θ(g(n)): 
	- Implies that f(n) belongs to both O(g(n)) and Ω(g(n))
	- The upper bound of the function f is denoted by Θ but the lower bound need not be in the same boundary
		- This is evident because, the inequality is true after a particular input size n<sub>0</sub>, the function f can have a best case value for the input size less than n<sub>0</sub> 
		- For example the best case for insertion sort is one iteration, and the worst case is n<sup>2</sup> iterations, the insertion sort has a time complexity of Θ(n<sup>2</sup>), but this does not cover the minimum runtime of the insertion sort
#### 2.2 Big O notation: O
- A function f(n) belongs to a family of functions O(g(n)) if there exists positive constants c, n<sub>0</sub> such that
	- 0 <=  f(n) <= cg(n) for all n >= n<sub>0</sub>
- Using Θ is more asymptotically tight, i.e. This describes the bounds of a function better than big O notation
- Using Big O only denotes the upper bound, this is not asymptotically tight always. Example 
	- Let the function f(n) belong to O(n). The function will also belong to O(n<sup>2</sup>). Both are correct, but the former is more asymptotically tight upper bound
#### 2.3 Big Omega notation: Ω
- A function f(n) belongs to a family of functions Ω(g(n)) if there exists positive constants c, n<sub>0</sub> such that
	- 0 <= cg(n) <= f(n) for all n >= n<sub>0</sub>
#### 2.4 Small o notation: o
- Used to denote the upper bound that is not asymptotically tight
- A function f(n) belongs to a family of functions o(g(n)) if there exists positive constant n<sub>0</sub> for all positive constant c > 0, the following inequality holds true
	- 0 <= f(n) < cg(n) for all n >= n<sub>0</sub> 
#### 2.5 Small omega notation: Ω 
- Used to denote the lower bound that is not asymptotically tight
- A function f(n) belongs to a family of functions Ω(g(n)) if there exists positive constant n<sub>0</sub> for all positive constant c > 0, the following inequality holds true
	- 0 <= cg(n) < f(n) for all n >= n<sub>0</sub> 

### 3. Average case analysis for Quick sort
- To perform the average case analysis, consider the key operation as comparing two elements
- E(X) = expectation of two elements being compared
- E(X) = E(ΣX<sub>ij</sub> ( for 1 <= i <= N-1 and j > i))
	- where X<sub>ij</sub> is a random var that equals 1 when the i<sup>th</sup> and j<sup>th</sup> elements in sorted order are compared and 0 other wise
- E(X) = ΣE(X<sub>ij</sub> ( for 1 <= i <= N-1 and j > i))
- E(X<sub>ij</sub>) = 2/(j - i + 1)
	- i<sup>th</sup> and j<sup>th</sup> are compare only when either one of the elements are picked as pivot, they are not compared when any element between them is picked.
	- When any element between them is picked as pivot, both the element will belong to different sub trees and will not be compared
- E(X) will belong to Θ(N\*log(N)), this can be obtained by expanding the summation, we will get a sum of a harmonic progression multiplied by n, which is n\*lg(n)
